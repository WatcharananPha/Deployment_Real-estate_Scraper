{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085b2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: Init -> สร้าง Chrome โปรไฟล์ถาวร\n",
      "Stage: Init -> เรียก Login\n",
      "Stage: Login -> เปิดหน้า m.facebook.com\n",
      "Stage: Login -> สำเร็จ\n",
      "Stage: Run -> เริ่มรวบรวมจากกลุ่มทั้งหมด\n",
      "Stage: Group 1/44 -> เริ่ม https://www.facebook.com/groups/302468990428489/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/302468990428489/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 1/44 -> สะสมทั้งหมด 0 URL\n",
      "Stage: Group 2/44 -> เริ่ม https://www.facebook.com/groups/322977734828852/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/322977734828852/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 2/44 -> สะสมทั้งหมด 0 URL\n",
      "Stage: Group 3/44 -> เริ่ม https://www.facebook.com/groups/812156038944325/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/812156038944325/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 3/44 -> สะสมทั้งหมด 0 URL\n",
      "Stage: Group 4/44 -> เริ่ม https://www.facebook.com/groups/1472146056424210/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1472146056424210/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 4/44 -> สะสมทั้งหมด 0 URL\n",
      "Stage: Group 5/44 -> เริ่ม https://www.facebook.com/groups/426467944402414/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/426467944402414/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 5/44 -> สะสมทั้งหมด 0 URL\n",
      "Stage: Group 6/44 -> เริ่ม https://www.facebook.com/groups/homerentcm/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/homerentcm/\n",
      "Stage: Group -> ได้ 582 URL (<=7 วัน)\n",
      "Stage: Group 6/44 -> สะสมทั้งหมด 582 URL\n",
      "Stage: Group 7/44 -> เริ่ม https://www.facebook.com/groups/509895225859790/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/509895225859790/\n",
      "Stage: Group -> ได้ 48 URL (<=7 วัน)\n",
      "Stage: Group 7/44 -> สะสมทั้งหมด 630 URL\n",
      "Stage: Group 8/44 -> เริ่ม https://www.facebook.com/groups/1299302030158649/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1299302030158649/\n",
      "Stage: Group -> ได้ 2 URL (<=7 วัน)\n",
      "Stage: Group 8/44 -> สะสมทั้งหมด 632 URL\n",
      "Stage: Group 9/44 -> เริ่ม https://www.facebook.com/groups/530492663958652/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/530492663958652/\n",
      "Stage: Group -> ได้ 193 URL (<=7 วัน)\n",
      "Stage: Group 9/44 -> สะสมทั้งหมด 825 URL\n",
      "Stage: Group 10/44 -> เริ่ม https://www.facebook.com/groups/596670275854317/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/596670275854317/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 10/44 -> สะสมทั้งหมด 825 URL\n",
      "Stage: Group 11/44 -> เริ่ม https://www.facebook.com/groups/cnxre/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/cnxre/\n",
      "Stage: Group -> ได้ 802 URL (<=7 วัน)\n",
      "Stage: Group 11/44 -> สะสมทั้งหมด 1627 URL\n",
      "Stage: Group 12/44 -> เริ่ม https://www.facebook.com/groups/1885263611797363/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1885263611797363/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 12/44 -> สะสมทั้งหมด 1627 URL\n",
      "Stage: Group 13/44 -> เริ่ม https://www.facebook.com/groups/1897854047114064/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1897854047114064/\n",
      "Stage: Group -> ได้ 393 URL (<=7 วัน)\n",
      "Stage: Group 13/44 -> สะสมทั้งหมด 2020 URL\n",
      "Stage: Group 14/44 -> เริ่ม https://www.facebook.com/groups/303531690102574/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/303531690102574/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 14/44 -> สะสมทั้งหมด 2020 URL\n",
      "Stage: Group 15/44 -> เริ่ม https://www.facebook.com/groups/1881982752029163/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1881982752029163/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 15/44 -> สะสมทั้งหมด 2020 URL\n",
      "Stage: Group 16/44 -> เริ่ม https://www.facebook.com/groups/568026117396809/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/568026117396809/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 16/44 -> สะสมทั้งหมด 2020 URL\n",
      "Stage: Group 17/44 -> เริ่ม https://www.facebook.com/groups/1928645537294336/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1928645537294336/\n",
      "Stage: Group -> ได้ 183 URL (<=7 วัน)\n",
      "Stage: Group 17/44 -> สะสมทั้งหมด 2203 URL\n",
      "Stage: Group 18/44 -> เริ่ม https://www.facebook.com/groups/298821664628156/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/298821664628156/\n",
      "Stage: Group -> ได้ 44 URL (<=7 วัน)\n",
      "Stage: Group 18/44 -> สะสมทั้งหมด 2247 URL\n",
      "Stage: Group 19/44 -> เริ่ม https://www.facebook.com/groups/903971886395138/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/903971886395138/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 19/44 -> สะสมทั้งหมด 2247 URL\n",
      "Stage: Group 20/44 -> เริ่ม https://www.facebook.com/groups/142702946428033/members\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/142702946428033/\n",
      "Stage: Group -> ได้ 1205 URL (<=7 วัน)\n",
      "Stage: Group 20/44 -> สะสมทั้งหมด 3452 URL\n",
      "Stage: Group 21/44 -> เริ่ม https://www.facebook.com/groups/250469775470436/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/250469775470436/\n",
      "Stage: Group -> ได้ 5 URL (<=7 วัน)\n",
      "Stage: Group 21/44 -> สะสมทั้งหมด 3457 URL\n",
      "Stage: Group 22/44 -> เริ่ม https://www.facebook.com/groups/1873094122912006/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1873094122912006/\n",
      "Stage: Group -> ได้ 677 URL (<=7 วัน)\n",
      "Stage: Group 22/44 -> สะสมทั้งหมด 4134 URL\n",
      "Stage: Group 23/44 -> เริ่ม https://www.facebook.com/groups/2083392538672247/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/2083392538672247/\n",
      "Stage: Group -> ได้ 4 URL (<=7 วัน)\n",
      "Stage: Group 23/44 -> สะสมทั้งหมด 4138 URL\n",
      "Stage: Group 24/44 -> เริ่ม https://www.facebook.com/groups/864193946960728/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/864193946960728/\n",
      "Stage: Group -> ได้ 839 URL (<=7 วัน)\n",
      "Stage: Group 24/44 -> สะสมทั้งหมด 4977 URL\n",
      "Stage: Group 25/44 -> เริ่ม https://www.facebook.com/groups/baanchiangmai/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/baanchiangmai/\n",
      "Stage: Group -> ได้ 31 URL (<=7 วัน)\n",
      "Stage: Group 25/44 -> สะสมทั้งหมด 5008 URL\n",
      "Stage: Group 26/44 -> เริ่ม https://www.facebook.com/groups/694087674785430/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/694087674785430/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 26/44 -> สะสมทั้งหมด 5008 URL\n",
      "Stage: Group 27/44 -> เริ่ม https://www.facebook.com/groups/411301775702951/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/411301775702951/\n",
      "Stage: Group -> ได้ 11 URL (<=7 วัน)\n",
      "Stage: Group 27/44 -> สะสมทั้งหมด 5019 URL\n",
      "Stage: Group 28/44 -> เริ่ม https://www.facebook.com/groups/169718747164928/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/169718747164928/\n",
      "Stage: Group -> ได้ 373 URL (<=7 วัน)\n",
      "Stage: Group 28/44 -> สะสมทั้งหมด 5392 URL\n",
      "Stage: Group 29/44 -> เริ่ม https://www.facebook.com/groups/1475061816108017/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1475061816108017/\n",
      "Stage: Group -> ได้ 397 URL (<=7 วัน)\n",
      "Stage: Group 29/44 -> สะสมทั้งหมด 5789 URL\n",
      "Stage: Group 30/44 -> เริ่ม https://www.facebook.com/groups/1582425938465943/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1582425938465943/\n",
      "Stage: Group -> ได้ 46 URL (<=7 วัน)\n",
      "Stage: Group 30/44 -> สะสมทั้งหมด 5835 URL\n",
      "Stage: Group 31/44 -> เริ่ม https://www.facebook.com/groups/sale.rent.poolvillachiangmai/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/sale.rent.poolvillachiangmai/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 31/44 -> สะสมทั้งหมด 5835 URL\n",
      "Stage: Group 32/44 -> เริ่ม https://www.facebook.com/groups/251125079442673/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/251125079442673/\n",
      "Stage: Group -> ได้ 1 URL (<=7 วัน)\n",
      "Stage: Group 32/44 -> สะสมทั้งหมด 5836 URL\n",
      "Stage: Group 33/44 -> เริ่ม https://www.facebook.com/groups/1034329704984830/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1034329704984830/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 33/44 -> สะสมทั้งหมด 5836 URL\n",
      "Stage: Group 34/44 -> เริ่ม https://www.facebook.com/groups/203683550205761/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/203683550205761/\n",
      "Stage: Group -> ได้ 155 URL (<=7 วัน)\n",
      "Stage: Group 34/44 -> สะสมทั้งหมด 5991 URL\n",
      "Stage: Group 35/44 -> เริ่ม https://www.facebook.com/groups/1450131905304596/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1450131905304596/\n",
      "Stage: Group -> ได้ 90 URL (<=7 วัน)\n",
      "Stage: Group 35/44 -> สะสมทั้งหมด 6081 URL\n",
      "Stage: Group 36/44 -> เริ่ม https://www.facebook.com/groups/959493160788393/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/959493160788393/\n",
      "Stage: Group -> ได้ 548 URL (<=7 วัน)\n",
      "Stage: Group 36/44 -> สะสมทั้งหมด 6629 URL\n",
      "Stage: Group 37/44 -> เริ่ม https://www.facebook.com/groups/2897034136980512/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/2897034136980512/\n",
      "Stage: Group -> ได้ 1193 URL (<=7 วัน)\n",
      "Stage: Group 37/44 -> สะสมทั้งหมด 7822 URL\n",
      "Stage: Group 38/44 -> เริ่ม https://www.facebook.com/groups/korn.property/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/korn.property/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 38/44 -> สะสมทั้งหมด 7822 URL\n",
      "Stage: Group 39/44 -> เริ่ม https://www.facebook.com/groups/1456428424593312/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/1456428424593312/\n",
      "Stage: Group -> ได้ 262 URL (<=7 วัน)\n",
      "Stage: Group 39/44 -> สะสมทั้งหมด 8084 URL\n",
      "Stage: Group 40/44 -> เริ่ม https://www.facebook.com/groups/152080739566471/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/152080739566471/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 40/44 -> สะสมทั้งหมด 8084 URL\n",
      "Stage: Group 41/44 -> เริ่ม https://www.facebook.com/groups/Land.House.C.M.2014/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/Land.House.C.M.2014/\n",
      "Stage: Group -> ได้ 376 URL (<=7 วัน)\n",
      "Stage: Group 41/44 -> สะสมทั้งหมด 8460 URL\n",
      "Stage: Group 42/44 -> เริ่ม https://www.facebook.com/groups/2336780789695894/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/2336780789695894/\n",
      "Stage: Group -> ได้ 0 URL (<=7 วัน)\n",
      "Stage: Group 42/44 -> สะสมทั้งหมด 8460 URL\n",
      "Stage: Group 43/44 -> เริ่ม https://www.facebook.com/groups/236116797208244/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/236116797208244/\n",
      "Stage: Group -> ได้ 40 URL (<=7 วัน)\n",
      "Stage: Group 43/44 -> สะสมทั้งหมด 8500 URL\n",
      "Stage: Group 44/44 -> เริ่ม https://www.facebook.com/groups/landhomechiangmai/\n",
      "Stage: Group -> เปิด https://m.facebook.com/groups/landhomechiangmai/\n",
      "Stage: Group -> ได้ 1571 URL (<=7 วัน)\n",
      "Stage: Group 44/44 -> สะสมทั้งหมด 10071 URL\n",
      "Stage: Save -> บันทึก CSV C:\\Users\\kongl\\Documents\\GitHub\\Real-Estate Listing Aggregator System\\Scraping\\Facebook_post_urls.csv จำนวน 10071 แถว\n",
      "Stage: Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "OUTPUT_CSV_FILE = r'data/Facebook_post_urls.csv'\n",
    "PROFILE_PATH = r'chrome-profile/fb-pipeline-stage1'\n",
    "\n",
    "GROUP_URLS = [\n",
    "    \"https://www.facebook.com/groups/302468990428489/\",\n",
    "    \"https://www.facebook.com/groups/322977734828852/\",\n",
    "    \"https://www.facebook.com/groups/812156038944325/\",\n",
    "    \"https://www.facebook.com/groups/1472146056424210/\",\n",
    "    \"https://www.facebook.com/groups/426467944402414/\",\n",
    "    \"https://www.facebook.com/groups/homerentcm/\",\n",
    "    \"https://www.facebook.com/groups/509895225859790/\",\n",
    "    \"https://www.facebook.com/groups/1299302030158649/\",\n",
    "    \"https://www.facebook.com/groups/530492663958652/\",\n",
    "    \"https://www.facebook.com/groups/596670275854317/\",\n",
    "    \"https://www.facebook.com/groups/cnxre/\",\n",
    "    \"https://www.facebook.com/groups/1885263611797363/\",\n",
    "    \"https://www.facebook.com/groups/1897854047114064/\",\n",
    "    \"https://www.facebook.com/groups/303531690102574/\",\n",
    "    \"https://www.facebook.com/groups/1881982752029163/\",\n",
    "    \"https://www.facebook.com/groups/568026117396809/\",\n",
    "    \"https://www.facebook.com/groups/1928645537294336/\",\n",
    "    \"https://www.facebook.com/groups/298821664628156/\",\n",
    "    \"https://www.facebook.com/groups/903971886395138/\",\n",
    "    \"https://www.facebook.com/groups/142702946428033/members\",\n",
    "    \"https://www.facebook.com/groups/250469775470436/\",\n",
    "    \"https://www.facebook.com/groups/1873094122912006/\",\n",
    "    \"https://www.facebook.com/groups/2083392538672247/\",\n",
    "    \"https://www.facebook.com/groups/864193946960728/\",\n",
    "    \"https://www.facebook.com/groups/baanchiangmai/\",\n",
    "    \"https://www.facebook.com/groups/694087674785430/\",\n",
    "    \"https://www.facebook.com/groups/411301775702951/\",\n",
    "    \"https://www.facebook.com/groups/169718747164928/\",\n",
    "    \"https://www.facebook.com/groups/1475061816108017/\",\n",
    "    \"https://www.facebook.com/groups/1582425938465943/\",\n",
    "    \"https://www.facebook.com/groups/sale.rent.poolvillachiangmai/\",\n",
    "    \"https://www.facebook.com/groups/251125079442673/\",\n",
    "    \"https://www.facebook.com/groups/1034329704984830/\",\n",
    "    \"https://www.facebook.com/groups/203683550205761/\",\n",
    "    \"https://www.facebook.com/groups/1450131905304596/\",\n",
    "    \"https://www.facebook.com/groups/959493160788393/\",\n",
    "    \"https://www.facebook.com/groups/2897034136980512/\",\n",
    "    \"https://www.facebook.com/groups/korn.property/\",\n",
    "    \"https://www.facebook.com/groups/1456428424593312/\",\n",
    "    \"https://www.facebook.com/groups/152080739566471/\",\n",
    "    \"https://www.facebook.com/groups/Land.House.C.M.2014/\",\n",
    "    \"https://www.facebook.com/groups/2336780789695894/\",\n",
    "    \"https://www.facebook.com/groups/236116797208244/\",\n",
    "    \"https://www.facebook.com/groups/landhomechiangmai/\"\n",
    "]\n",
    "\n",
    "def login_to_facebook(driver):\n",
    "    print(\"Login -> opening m.facebook.com\")\n",
    "    driver.get(\"https://m.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    for s in [\"button[data-cookiebanner='accept_button_dialog']\", \"button[title='Allow all cookies']\", \"button[title='Accept All']\", \"button[aria-label='Allow all cookies']\"]:\n",
    "        btns = driver.find_elements(By.CSS_SELECTOR, s)\n",
    "        if btns and btns[0].is_displayed():\n",
    "            btns[0].click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "    email = driver.find_elements(By.ID, \"m_login_email\")\n",
    "    pwd = driver.find_elements(By.ID, \"m_login_password\")\n",
    "    if not email:\n",
    "        email = driver.find_elements(By.ID, \"email\")\n",
    "        pwd = driver.find_elements(By.ID, \"pass\")\n",
    "    if email and pwd:\n",
    "        email[0].clear()\n",
    "        email[0].send_keys(FACEBOOK_EMAIL)\n",
    "        pwd[0].send_keys(FACEBOOK_PASSWORD)\n",
    "        pwd[0].send_keys(Keys.RETURN)\n",
    "        WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"a[aria-label='Menu'], a[aria-label='Home'], a[aria-label='Search']\")))\n",
    "    print(\"Login -> completed\")\n",
    "\n",
    "def parse_relative_time_to_days(time_str):\n",
    "    s = (time_str or \"\").strip().lower()\n",
    "    if not s or \"เมื่อสักครู่\" in s or \"just now\" in s:\n",
    "        return 0\n",
    "    if \"นาที\" in s or \"minute\" in s or \"min\" in s or \"ชม\" in s or \"ชั่วโมง\" in s or \"hour\" in s or \"hrs\" in s or \"hr\" in s:\n",
    "        return 0\n",
    "    m = re.search(r'(\\d+)', s)\n",
    "    n = int(m.group(1)) if m else 0\n",
    "    if \"วัน\" in s or \"day\" in s or \"d\" == s[-1:]:\n",
    "        return n\n",
    "    if \"สัปดาห์\" in s or \"week\" in s or \"wk\" in s or \"w\" == s[-1:]:\n",
    "        return n * 7\n",
    "    if \"เดือน\" in s or \"month\" in s or \"mo\" in s:\n",
    "        return n * 30\n",
    "    if \"ปี\" in s or \"year\" in s or \"yr\" in s:\n",
    "        return n * 365\n",
    "    return 999\n",
    "\n",
    "def wait_present(driver, by, sel, timeout):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < timeout:\n",
    "        if driver.find_elements(by, sel):\n",
    "            return True\n",
    "        time.sleep(0.25)\n",
    "    return False\n",
    "\n",
    "def page_loaded(driver):\n",
    "    try_len = driver.execute_script(\"return document.body && document.body.innerHTML ? document.body.innerHTML.length : 0\")\n",
    "    return try_len and try_len > 1000\n",
    "\n",
    "def human_reload_flow(driver, url):\n",
    "    driver.get(url)\n",
    "    ok = wait_present(driver, By.CSS_SELECTOR, \"div[role='main'], #m_group_stories_container, article\", 8)\n",
    "    if ok or page_loaded(driver):\n",
    "        return True\n",
    "    driver.refresh()\n",
    "    ok = wait_present(driver, By.CSS_SELECTOR, \"div[role='main'], #m_group_stories_container, article\", 8)\n",
    "    if ok or page_loaded(driver):\n",
    "        return True\n",
    "    driver.get(\"https://www.livinginsider.com/\")\n",
    "    time.sleep(1.2)\n",
    "    driver.get(url)\n",
    "    ok = wait_present(driver, By.CSS_SELECTOR, \"div[role='main'], #m_group_stories_container, article\", 8)\n",
    "    return ok or page_loaded(driver)\n",
    "\n",
    "def normalize_group_url(u):\n",
    "    v = u.strip().replace(\"://facebook.com\", \"://www.facebook.com\").replace(\"://www.facebook.com\", \"://m.facebook.com\")\n",
    "    if \"/members\" in v:\n",
    "        v = v.split(\"/members\")[0] + \"/\"\n",
    "    return v if v.endswith(\"/\") else v + \"/\"\n",
    "\n",
    "def collect_group_post_urls(driver, group_url):\n",
    "    group_url = normalize_group_url(group_url)\n",
    "    print(f\"Group -> loading {group_url}\")\n",
    "    ok_nav = human_reload_flow(driver, group_url)\n",
    "    if not ok_nav:\n",
    "        print(\"Group -> load failed, skipping\")\n",
    "        return []\n",
    "    seen = set()\n",
    "    results = []\n",
    "    prev_len = 0\n",
    "    stagnant = 0\n",
    "    loops = 0\n",
    "    while True:\n",
    "        data = driver.execute_script(\"\"\"\n",
    "            function absUrl(href){ if(!href) return null; if(href.indexOf('http')===0) return href.split('?')[0]; return location.origin + href.split('?')[0]; }\n",
    "            var posts = Array.from(document.querySelectorAll('article, div[role=\"article\"]'));\n",
    "            var out = [];\n",
    "            for (var i=0;i<posts.length;i++){\n",
    "                var p = posts[i];\n",
    "                var a = p.querySelector(\"a[href*='/posts/'], a[href*='/permalink/'], a[href*='story.php']\");\n",
    "                if(!a) continue;\n",
    "                var href = absUrl(a.getAttribute('href'));\n",
    "                if(!href) continue;\n",
    "                var t = p.querySelector(\"a[aria-label], time[aria-label], abbr[aria-label]\");\n",
    "                var tlabel = null;\n",
    "                if(t){ tlabel = t.getAttribute('aria-label') || t.textContent || \"\"; }\n",
    "                if(!tlabel){\n",
    "                    var t2 = p.querySelector(\"span[aria-label], div[aria-label]\");\n",
    "                    if(t2){ tlabel = t2.getAttribute('aria-label') || t2.textContent || \"\"; }\n",
    "                }\n",
    "                var ut = null;\n",
    "                var uel = p.querySelector('abbr[data-utime], time[data-utime]');\n",
    "                if(uel){ var v = parseInt(uel.getAttribute('data-utime')); if(!isNaN(v)) ut = v; }\n",
    "                out.push([href, tlabel, ut]);\n",
    "            }\n",
    "            return out;\n",
    "        \"\"\")\n",
    "        for href, tlabel, ut in data:\n",
    "            if href in seen:\n",
    "                continue\n",
    "            days_ago = parse_relative_time_to_days(tlabel)\n",
    "            if (days_ago == 999) and ut:\n",
    "                now_epoch = int(datetime.now(timezone.utc).timestamp())\n",
    "                diff_days = int((now_epoch - int(ut)) // 86400)\n",
    "                days_ago = diff_days if diff_days >= 0 else 999\n",
    "            seen.add(href)\n",
    "            if days_ago <= 7:\n",
    "                results.append(href)\n",
    "            elif days_ago > 7:\n",
    "                return results\n",
    "        driver.execute_script(\"window.scrollBy(0, 1400);\")\n",
    "        time.sleep(1.4)\n",
    "        curr_len = len(seen)\n",
    "        if curr_len == prev_len:\n",
    "            stagnant += 1\n",
    "        else:\n",
    "            stagnant = 0\n",
    "        prev_len = curr_len\n",
    "        loops += 1\n",
    "        if stagnant >= 6 or loops >= 3000:\n",
    "            break\n",
    "    print(f\"Group -> collected {len(results)} URLs (<=7 days)\")\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    out_dir = Path(os.path.dirname(OUTPUT_CSV_FILE))\n",
    "    if out_dir and not out_dir.exists():\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Init -> creating Chrome profile\")\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(f\"--user-data-dir={PROFILE_PATH}\")\n",
    "    options.page_load_strategy = \"eager\"\n",
    "    driver = uc.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(90)\n",
    "    driver.set_script_timeout(90)\n",
    "    login_to_facebook(driver)\n",
    "    print(\"Run -> collecting from all groups\")\n",
    "    rows = []\n",
    "    total = 0\n",
    "    for i, link in enumerate(GROUP_URLS, start=1):\n",
    "        print(f\"Group {i}/{len(GROUP_URLS)} -> starting\")\n",
    "        urls = collect_group_post_urls(driver, link)\n",
    "        for u in urls:\n",
    "            rows.append({'group_name': link.split(\"/groups/\")[1].split(\"/\")[0], 'group_url': link, 'post_url': u})\n",
    "        total += len(urls)\n",
    "        print(f\"Group {i}/{len(GROUP_URLS)} -> total {total} URLs\")\n",
    "        time.sleep(1.0)\n",
    "    driver.quit()\n",
    "    print(f\"Save -> writing CSV {OUTPUT_CSV_FILE} with {len(rows)} rows\")\n",
    "    df_out = pd.DataFrame(rows, columns=['group_name', 'group_url', 'post_url'])\n",
    "    df_out.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig')\n",
    "    print(\"Done\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "INPUT_LINKS_CSV = Path(\"data/Facebook_post_urls.csv\")\n",
    "OUTPUT_DETAILS_CSV = Path(\"data/facebook_full_content.csv\")\n",
    "PROFILE_PATH = Path(\"chrome-profile/fb-scraper\")\n",
    "WAIT = 30\n",
    "\n",
    "def click_cookie(driver):\n",
    "    for s in ['button[data-cookiebanner=\"accept_button\"]', 'button[data-cookiebanner=\"accept_button_dialog\"]', \"button[title='Allow all cookies']\", \"button[aria-label='Allow all cookies']\", \"div[role='dialog'] div[aria-label*='cookies'] button\"]:\n",
    "        btns = driver.find_elements(By.CSS_SELECTOR, s)\n",
    "        if btns and btns[0].is_displayed() and btns[0].is_enabled():\n",
    "            btns[0].click()\n",
    "            time.sleep(1)\n",
    "            break\n",
    "\n",
    "def login(driver):\n",
    "    driver.get(\"https://www.facebook.com/?locale=en_US\")\n",
    "    time.sleep(2)\n",
    "    click_cookie(driver)\n",
    "    if \"login\" in driver.current_url.lower():\n",
    "        WebDriverWait(driver, WAIT).until(EC.presence_of_element_located((By.ID, \"email\"))).send_keys(FACEBOOK_EMAIL)\n",
    "        driver.find_element(By.ID, \"pass\").send_keys(FACEBOOK_PASSWORD)\n",
    "        driver.find_element(By.NAME, \"login\").click()\n",
    "    WebDriverWait(driver, WAIT).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"main\"]')))\n",
    "\n",
    "def expand_see_more(driver, root):\n",
    "    driver.execute_script(\"\"\"\n",
    "        (function(root){\n",
    "          function clickAll(){\n",
    "            var q = (root||document).querySelectorAll(\"div[role='button'],span[role='button'],a[role='button']\");\n",
    "            var did=false;\n",
    "            for (var i=0;i<q.length;i++){\n",
    "              var t=(q[i].innerText||\"\").trim();\n",
    "              if(!t) continue;\n",
    "              if(t.includes(\"See more\")||t.includes(\"See More\")||t.includes(\"ดูเพิ่มเติม\")||t.includes(\"เพิ่มเติม\")){\n",
    "                q[i].click();did=true;\n",
    "              }\n",
    "            }\n",
    "            return did;\n",
    "          }\n",
    "          var n=0; while(n<4 && clickAll()){ n++; }\n",
    "        })(arguments[0]);\n",
    "    \"\"\", root)\n",
    "\n",
    "def extract_text(driver):\n",
    "    txt = driver.execute_script(\"\"\"\n",
    "        function pick(){\n",
    "          var sels=[\n",
    "            \"div[role='dialog'] [data-ad-rendering-role='story_message']\",\n",
    "            \"div[role='main']  [data-ad-rendering-role='story_message']\",\n",
    "            \"div[role='dialog'] [data-ad-preview='message']\",\n",
    "            \"div[role='main']  [data-ad-preview='message']\",\n",
    "            \"div[role='dialog'] article\",\n",
    "            \"div[role='main']  article\"\n",
    "          ];\n",
    "          for(var i=0;i<sels.length;i++){\n",
    "            var e=document.querySelector(sels[i]);\n",
    "            if(e){ return e; }\n",
    "          }\n",
    "          return document.querySelector(\"div[role='dialog']\")||document.querySelector(\"div[role='main']\");\n",
    "        }\n",
    "        var el=pick();\n",
    "        return el? (el.textContent||\"\").trim() : \"\";\n",
    "    \"\"\")\n",
    "    if not txt:\n",
    "        return \"\"\n",
    "    for b in [\"Like\",\"Comment\",\"Share\",\"Send\",\"Follow\",\"Save\",\"More\",\"ถูกใจ\",\"แสดงความคิดเห็น\",\"แชร์\",\"ส่งข้อความ\",\"บันทึก\",\"ติดตาม\"]:\n",
    "        txt = txt.replace(b, \" \")\n",
    "    return \" \".join(txt.split()).strip()\n",
    "\n",
    "def get_raw_post_text(driver, permalink):\n",
    "    for step in range(3):\n",
    "        driver.get(permalink)\n",
    "        WebDriverWait(driver, WAIT).until(EC.any_of(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='dialog']\")),\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div[role='main']\"))\n",
    "        ))\n",
    "        root = driver.find_elements(By.CSS_SELECTOR, \"div[role='dialog'], div[role='main']\")\n",
    "        if root:\n",
    "            expand_see_more(driver, root[0])\n",
    "        text = extract_text(driver)\n",
    "        if len(text) > 20:\n",
    "            return text\n",
    "        if step == 0:\n",
    "            driver.refresh()\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            driver.get(\"https://www.facebook.com/\")\n",
    "            time.sleep(1.5)\n",
    "    return \"\"\n",
    "\n",
    "if not FACEBOOK_EMAIL or not FACEBOOK_PASSWORD or not INPUT_LINKS_CSV.exists():\n",
    "    raise SystemExit(1)\n",
    "\n",
    "opts = uc.ChromeOptions()\n",
    "opts.add_argument(f'--user-data-dir={PROFILE_PATH.as_posix()}')\n",
    "opts.add_argument('--disable-notifications')\n",
    "opts.add_argument('--lang=en-US')\n",
    "opts.page_load_strategy = \"eager\"\n",
    "driver = uc.Chrome(options=opts, version_main=142)\n",
    "driver.set_page_load_timeout(90)\n",
    "driver.set_script_timeout(90)\n",
    "\n",
    "login(driver)\n",
    "\n",
    "with open(INPUT_LINKS_CSV, 'r', encoding='utf-8-sig', newline='') as infile, open(OUTPUT_DETAILS_CSV, 'w', newline='', encoding='utf-8-sig') as outfile:\n",
    "    r = csv.DictReader(infile)\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['post_url', 'content'])\n",
    "    for row in r:\n",
    "        url = (row.get('post_url') or '').strip()\n",
    "        if not url:\n",
    "            continue\n",
    "        txt = get_raw_post_text(driver, url) or \"N/A\"\n",
    "        w.writerow([url, txt])\n",
    "        time.sleep(1.2)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd43bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Chrome Driver...\n",
      "Navigating to start URL: https://www.ddproperty.com/%E0%B8%A3%E0%B8%A7%E0%B8%A1%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%81%E0%B8%B2%E0%B8%A8%E0%B8%82%E0%B8%B2%E0%B8%A2?listingType=sale&regionCode=TH50&locale=th&slug=search&_freetextDisplay=%E0%B9%80%E0%B8%8A%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B9%83%E0%B8%AB%E0%B8%A1%E0%B9%88&isCommercial=false\n",
      "\n",
      "--- Scraping Page 1 ---\n",
      "Found 23 new listing URLs on this page.\n",
      "\n",
      "--- Scraping Page 2 ---\n",
      "Found 20 new listing URLs on this page.\n",
      "\n",
      "--- Scraping Page 3 ---\n",
      "Found 20 new listing URLs on this page.\n",
      "\n",
      "--- Scraping Page 4 ---\n",
      "Found 20 new listing URLs on this page.\n",
      "\n",
      "--- Scraping Page 5 ---\n",
      "Found 20 new listing URLs on this page.\n",
      "Next page did not change within timeout. Ending pagination.\n",
      "\n",
      "Total unique URLs collected: 103\n",
      "Writing all URLs to ddproperty_listing_urls.csv...\n",
      "Process complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "START_URL = 'https://www.ddproperty.com/%E0%B8%A3%E0%B8%A7%E0%B8%A1%E0%B8%9B%E0%B8%A3%E0%B8%B0%E0%B8%81%E0%B8%B2%E0%B8%A8%E0%B8%82%E0%B8%B2%E0%B8%A2?areaCode=&listingType=sale&regionCode=TH50&locale=th&slug=search&_freetextDisplay=%E0%B9%80%E0%B8%8A%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B9%83%E0%B8%AB%E0%B8%A1%E0%B9%88&isCommercial=false'\n",
    "OUTPUT_CSV_FILE = 'data/ddproperty_listing_urls.csv'\n",
    "WEBDRIVER_WAIT_TIMEOUT = 20\n",
    "MAX_PAGES = 200\n",
    "\n",
    "MONTH_ABBR = r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)'\n",
    "DATE_REGEX = re.compile(rf'\\b{MONTH_ABBR}\\s+\\d{{1,2}},\\s+\\d{{4}}\\b', re.I)\n",
    "REL_REGEX = re.compile(r'(\\d+)\\s*(h|d|w|mo|y)\\s*ago', re.I)\n",
    "TH_TZ = timezone(timedelta(hours=7))\n",
    "\n",
    "def build_page_url(start_url, page):\n",
    "    u = urlparse(start_url)\n",
    "    q = urlencode(dict(parse_qsl(u.query)), doseq=True)\n",
    "    path = u.path.rstrip('/')\n",
    "    m = re.match(r'^(.*?)(/\\d+)$', path)\n",
    "    base = m.group(1) if m else path\n",
    "    new_path = base if page <= 1 else base + f'/{page}'\n",
    "    return urlunparse((u.scheme, u.netloc, new_path, u.params, q, u.fragment))\n",
    "\n",
    "def within_30_days(text):\n",
    "    now = datetime.now(TH_TZ)\n",
    "    m = DATE_REGEX.search(text)\n",
    "    if m:\n",
    "        dt = datetime.strptime(m.group(0), \"%b %d, %Y\").date()\n",
    "        delta = (now.date() - dt).days\n",
    "        return 0 <= delta <= 30\n",
    "    m2 = REL_REGEX.search(text)\n",
    "    if m2:\n",
    "        n = int(m2.group(1))\n",
    "        unit = m2.group(2).lower()\n",
    "        if unit == 'h':\n",
    "            return True\n",
    "        if unit == 'd':\n",
    "            return n <= 30\n",
    "        if unit == 'w':\n",
    "            return n * 7 <= 30\n",
    "        if unit == 'mo':\n",
    "            return n * 30 <= 30\n",
    "        if unit == 'y':\n",
    "            return n * 365 <= 30\n",
    "    return False\n",
    "\n",
    "print(\"Init Chrome Driver...\")\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument('--disable-notifications')\n",
    "options.add_argument('--start-maximized')\n",
    "driver = uc.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "\n",
    "first_url = build_page_url(START_URL, 1)\n",
    "print(f\"Navigate to: {first_url}\")\n",
    "driver.get(first_url)\n",
    "\n",
    "btns = driver.find_elements(By.XPATH, \"//button[normalize-space(text())='ยอมรับ']\")\n",
    "if btns:\n",
    "    btns[0].click()\n",
    "    time.sleep(1)\n",
    "\n",
    "all_listing_urls = set()\n",
    "page_num = 1\n",
    "last_first_href = \"\"\n",
    "\n",
    "while page_num <= MAX_PAGES:\n",
    "    print(f\"Scraping page {page_num}\")\n",
    "    listing_sel = \"a.listing-card-link, a.card-footer\"\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, listing_sel)))\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(0.4)\n",
    "\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, listing_sel)\n",
    "    hrefs_now = [e.get_attribute('href') for e in cards if e.get_attribute('href')]\n",
    "    if not hrefs_now:\n",
    "        print(\"No URLs found, stopping\")\n",
    "        break\n",
    "    if page_num > 1 and hrefs_now[0] == last_first_href:\n",
    "        print(\"Listing unchanged, stopping\")\n",
    "        break\n",
    "    last_first_href = hrefs_now[0]\n",
    "\n",
    "    hrefs_filtered = []\n",
    "    for e in cards:\n",
    "        h = e.get_attribute('href')\n",
    "        if not h:\n",
    "            continue\n",
    "        rec_nodes = e.find_elements(By.XPATH, \".//span[@da-id='lc-feature-info' or contains(@class,'info-value') or (contains(@class,'pg-font-caption-xs') and contains(., 'โพสต์อีกครั้งเมื่อ'))]\")\n",
    "        if not rec_nodes:\n",
    "            anc = None\n",
    "            try:\n",
    "                anc = e.find_element(By.XPATH, \"./ancestor::div[contains(@class,'details-group-root') or contains(@class,'listing-card') or contains(@class,'content')][1]\")\n",
    "            except:\n",
    "                pass\n",
    "            if anc:\n",
    "                rec_nodes = anc.find_elements(By.XPATH, \".//span[@da-id='lc-feature-info' or contains(@class,'info-value') or (contains(@class,'pg-font-caption-xs') and contains(., 'โพสต์อีกครั้งเมื่อ'))]\")\n",
    "        rec_text = rec_nodes[0].text if rec_nodes else e.text\n",
    "        if within_30_days(rec_text):\n",
    "            hrefs_filtered.append(h)\n",
    "\n",
    "    new_urls = set(hrefs_filtered) - all_listing_urls\n",
    "    print(f\"Found {len(new_urls)} new URLs on page\")\n",
    "    all_listing_urls.update(hrefs_filtered)\n",
    "\n",
    "    next_num = page_num + 1\n",
    "    next_url = build_page_url(START_URL, next_num)\n",
    "    prev_last = hrefs_now[-1]\n",
    "    driver.get(next_url)\n",
    "\n",
    "    t0 = time.time()\n",
    "    changed = False\n",
    "    while time.time() - t0 < WEBDRIVER_WAIT_TIMEOUT:\n",
    "        state = driver.execute_script(\"return document.readyState\")\n",
    "        if state == \"complete\":\n",
    "            els = driver.find_elements(By.CSS_SELECTOR, listing_sel)\n",
    "            if els:\n",
    "                h = els[0].get_attribute('href')\n",
    "                hh = els[-1].get_attribute('href')\n",
    "                if (h and h != last_first_href) or (hh and hh != prev_last):\n",
    "                    changed = True\n",
    "                    break\n",
    "        time.sleep(0.3)\n",
    "    if not changed:\n",
    "        print(\"Next page unchanged, stopping\")\n",
    "        break\n",
    "\n",
    "    page_num = next_num\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "if all_listing_urls:\n",
    "    print(f\"Total URLs: {len(all_listing_urls)}\")\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['url'])\n",
    "        for url in sorted(all_listing_urls):\n",
    "            w.writerow([url])\n",
    "    print(\"Process complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8543cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "INPUT_CSV_FILE = 'data/ddproperty_listing_urls.csv'\n",
    "OUTPUT_CSV_FILE = 'data/ddproperty_scraped_details.csv'\n",
    "WEBDRIVER_WAIT_TIMEOUT = 25\n",
    "PROCESSES = max(1, min(cpu_count(), 4))\n",
    "\n",
    "def text_or_empty(driver, css):\n",
    "    els = driver.find_elements(By.CSS_SELECTOR, css)\n",
    "    return els[0].text.strip() if els else \"\"\n",
    "\n",
    "def first_el(driver, css):\n",
    "    els = driver.find_elements(By.CSS_SELECTOR, css)\n",
    "    return els[0] if els else None\n",
    "\n",
    "def click_js(driver, el):\n",
    "    driver.execute_script(\"arguments[0].click();\", el)\n",
    "\n",
    "def any_visible(driver, selector):\n",
    "    return driver.execute_script(\"\"\"\n",
    "        const sel = arguments[0];\n",
    "        const els = document.querySelectorAll(sel);\n",
    "        for (const el of els) {\n",
    "            const cs = getComputedStyle(el);\n",
    "            const r = el.getBoundingClientRect();\n",
    "            if (cs.display !== 'none' && cs.visibility !== 'hidden' && parseFloat(cs.opacity) !== 0 && r.width > 0 && r.height > 0) {\n",
    "                return true;\n",
    "            }\n",
    "        }\n",
    "        return false;\n",
    "    \"\"\", selector)\n",
    "\n",
    "def close_modal(driver, body_selectors):\n",
    "    for sel in body_selectors:\n",
    "        if any_visible(driver, sel):\n",
    "            btn = first_el(driver, \"button[da-id='modal-close-button'], button.btn-close, button[aria-label='Close']\")\n",
    "            if btn:\n",
    "                click_js(driver, btn)\n",
    "            t0 = time.time()\n",
    "            while any_visible(driver, sel) and time.time() - t0 < WEBDRIVER_WAIT_TIMEOUT:\n",
    "                time.sleep(0.2)\n",
    "            return\n",
    "\n",
    "def scrape_listing(driver, url):\n",
    "    wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "    details = {'URL': url}\n",
    "    driver.get(url)\n",
    "    btns = driver.find_elements(By.XPATH, \"//button[normalize-space(text())='ยอมรับ']\")\n",
    "    if btns:\n",
    "        click_js(driver, btns[0])\n",
    "        time.sleep(1)\n",
    "    main_sel = \"div[da-id='property-snapshot-info']\"\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, main_sel)))\n",
    "    details['Title'] = text_or_empty(driver, \"h1[da-id='property-title']\")\n",
    "    details['Address'] = text_or_empty(driver, \"p[da-id='property-address']\")\n",
    "    price_txt = text_or_empty(driver, \"h2[da-id='price-amount']\")\n",
    "    details['Price'] = price_txt.replace('฿', '').strip()\n",
    "    for a in driver.find_elements(By.CSS_SELECTOR, \"div.amenity[da-id*='-amenity']\"):\n",
    "        labels = [i.get_attribute('aria-label') for i in a.find_elements(By.TAG_NAME, 'img') if i.get_attribute('aria-label')]\n",
    "        val_el = a.find_elements(By.CSS_SELECTOR, \"p.amenity-text\")\n",
    "        if labels and val_el:\n",
    "            details[labels[0]] = val_el[0].text.strip()\n",
    "    see_more_btn = first_el(driver, \"button[da-id='meta-table-see-more-btn'], button[da-id='see-more-meta']\")\n",
    "    if see_more_btn:\n",
    "        click_js(driver, see_more_btn)\n",
    "        modal_sel = \"div.property-modal-body\"\n",
    "        wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, modal_sel)))\n",
    "        modal = first_el(driver, modal_sel)\n",
    "        if modal:\n",
    "            for w in modal.find_elements(By.CSS_SELECTOR, \"div.property-modal-body-wrapper\"):\n",
    "                alts = [i.get_attribute('alt') for i in w.find_elements(By.TAG_NAME, 'img') if i.get_attribute('alt')]\n",
    "                val_el = w.find_elements(By.CSS_SELECTOR, \"p.property-modal-body-value\")\n",
    "                if alts and val_el:\n",
    "                    key = alts[0].replace('-o', '').replace('-', ' ').title()\n",
    "                    details[key] = val_el[0].text.strip()\n",
    "        close_modal(driver, [modal_sel])\n",
    "    read_btn = first_el(driver, \"button[da-id='description-widget-show-more-lnk'], button[da-id='property-description-show-more']\")\n",
    "    if read_btn:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", read_btn)\n",
    "        time.sleep(0.5)\n",
    "        click_js(driver, read_btn)\n",
    "        desc_modal_sels = [\"div.description-modal-body\", \"div[da-id='description-modal-body']\"]\n",
    "        expanded_sels = [\"div[da-id='description-widget-body']\", \"div[da-id='description-text']\", \"div.property-description\"]\n",
    "        desc_body = None\n",
    "        t0 = time.time()\n",
    "        while time.time() - t0 < WEBDRIVER_WAIT_TIMEOUT:\n",
    "            for sel in desc_modal_sels:\n",
    "                el = first_el(driver, sel)\n",
    "                if el and any_visible(driver, sel):\n",
    "                    desc_body = el\n",
    "                    break\n",
    "            if desc_body:\n",
    "                break\n",
    "            for sel in expanded_sels:\n",
    "                el = first_el(driver, sel)\n",
    "                if el and el.text.strip():\n",
    "                    details['Description'] = el.text.strip()\n",
    "                    desc_body = None\n",
    "                    break\n",
    "            if 'Description' in details:\n",
    "                break\n",
    "            time.sleep(0.2)\n",
    "        if desc_body:\n",
    "            html = desc_body.get_attribute('innerHTML') or \"\"\n",
    "            details['Description'] = html.replace('<br>', '\\n').strip()\n",
    "            close_modal(driver, desc_modal_sels)\n",
    "        if 'Description' not in details:\n",
    "            details['Description'] = text_or_empty(driver, \"div[da-id='description-widget-body']\")\n",
    "    return details\n",
    "\n",
    "def run_batch(urls):\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument('--disable-notifications')\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.page_load_strategy = 'eager'\n",
    "    driver = uc.Chrome(options=options)\n",
    "    driver.set_page_load_timeout(180)\n",
    "    out = []\n",
    "    for url in urls:\n",
    "        out.append(scrape_listing(driver, url))\n",
    "        time.sleep(2.0)\n",
    "    driver.quit()\n",
    "    return out\n",
    "\n",
    "def chunk(seq, size):\n",
    "    return [seq[i:i+size] for i in range(0, len(seq), size)]\n",
    "\n",
    "with open(INPUT_CSV_FILE, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    urls_to_scrape = [row[0] for row in reader if row and row[0].strip()]\n",
    "\n",
    "if not urls_to_scrape:\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        csv.DictWriter(f, fieldnames=['URL']).writeheader()\n",
    "else:\n",
    "    batch_size = max(1, (len(urls_to_scrape) + PROCESSES - 1) // PROCESSES)\n",
    "    with Pool(PROCESSES) as pool:\n",
    "        results = pool.map(run_batch, chunk(urls_to_scrape, batch_size))\n",
    "    all_details = [d for batch in results for d in batch]\n",
    "    headers = sorted({\"URL\"} | {k for d in all_details for k in d.keys()})\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=headers)\n",
    "        w.writeheader()\n",
    "        w.writerows(all_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3cb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import re\n",
    "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "START_URL = 'https://www.livinginsider.com/living_zone/45/all/all/1/%E0%B9%80%E0%B8%8A%E0%B8%B5%E0%B8%A2%E0%B8%87%E0%B9%83%E0%B8%AB%E0%B8%A1%E0%B9%88.html'\n",
    "OUTPUT_CSV_FILE = 'data/livinginsider_listing_urls.csv'\n",
    "PAGE_TIMEOUT = 45\n",
    "MAX_PAGES = 200\n",
    "\n",
    "def build_page_url(u, page):\n",
    "    p = urlparse(u)\n",
    "    parts = [x for x in p.path.split('/') if x]\n",
    "    k = None\n",
    "    for i, seg in enumerate(parts):\n",
    "        if re.fullmatch(r'\\d+', seg):\n",
    "            k = i\n",
    "    if k is None:\n",
    "        base = p.path.rstrip('/')\n",
    "        new_path = base if page <= 1 else base + f'/{page}'\n",
    "    else:\n",
    "        parts[k] = '1' if page <= 1 else str(page)\n",
    "        new_path = '/' + '/'.join(parts)\n",
    "    return urlunparse((p.scheme, p.netloc, new_path, p.params, urlencode(dict(parse_qsl(p.query)), doseq=True), p.fragment))\n",
    "\n",
    "def wait_ready(driver, timeout):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < timeout:\n",
    "        if driver.execute_script(\"return document.readyState\") == \"complete\":\n",
    "            return True\n",
    "        time.sleep(0.2)\n",
    "    return False\n",
    "\n",
    "def deep_scroll(driver, rounds=18, pause=0.7):\n",
    "    h0 = 0\n",
    "    for _ in range(rounds):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(pause)\n",
    "        h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if h == h0:\n",
    "            break\n",
    "        h0 = h\n",
    "\n",
    "def collect_links_js(driver, base):\n",
    "    hrefs = driver.execute_script(\"\"\"\n",
    "const out = [];\n",
    "const a1 = Array.from(document.querySelectorAll(\"a[href*='/livingdetail/'][href$='.html']\"));\n",
    "const a2 = Array.from(document.querySelectorAll(\"a[href^='/livingdetail/'][href$='.html']\"));\n",
    "const all = [...a1, ...a2];\n",
    "for (const a of all){\n",
    "  const h = a.getAttribute('href') || '';\n",
    "  if (h && !h.includes('bclick') && !h.includes('stories') && !h.includes('banner')){\n",
    "    out.push(h);\n",
    "  }\n",
    "}\n",
    "return Array.from(new Set(out));\n",
    "\"\"\")\n",
    "    fixed = []\n",
    "    for h in hrefs:\n",
    "        fixed.append(base + h if h.startswith(\"/\") else h)\n",
    "    return list(dict.fromkeys(fixed))\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument('--disable-notifications')\n",
    "options.add_argument('--start-maximized')\n",
    "driver = uc.Chrome(options=options)\n",
    "base = f\"{urlparse(START_URL).scheme}://{urlparse(START_URL).netloc}\"\n",
    "\n",
    "page = 1\n",
    "all_urls = set()\n",
    "last_first = \"\"\n",
    "driver.get(build_page_url(START_URL, page))\n",
    "wait_ready(driver, PAGE_TIMEOUT)\n",
    "\n",
    "while page <= MAX_PAGES:\n",
    "    deep_scroll(driver, rounds=20, pause=0.8)\n",
    "    urls_now = collect_links_js(driver, base)\n",
    "    if not urls_now:\n",
    "        break\n",
    "    if page > 1 and urls_now[0] == last_first:\n",
    "        break\n",
    "    last_first = urls_now[0]\n",
    "    all_urls.update(urls_now)\n",
    "\n",
    "    page += 1\n",
    "    prev_last = urls_now[-1]\n",
    "    driver.get(build_page_url(START_URL, page))\n",
    "    t0 = time.time()\n",
    "    changed = False\n",
    "    while time.time() - t0 < PAGE_TIMEOUT:\n",
    "        wait_ready(driver, 3)\n",
    "        deep_scroll(driver, rounds=6, pause=0.6)\n",
    "        cur = collect_links_js(driver, base)\n",
    "        if cur and (cur[0] != last_first or cur[-1] != prev_last):\n",
    "            changed = True\n",
    "            break\n",
    "        time.sleep(0.3)\n",
    "    if not changed:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "if all_urls:\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['url'])\n",
    "        for u in sorted(all_urls):\n",
    "            w.writerow([u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "INPUT_CSV = Path(\"data/livinginsider_listing_urls.csv\")\n",
    "OUTPUT_CSV = \"data/livinginsider_scraped_details.csv\"\n",
    "\n",
    "def first_text(elems):\n",
    "    return elems[0].text.strip() if elems else \"\"\n",
    "\n",
    "if not INPUT_CSV.exists():\n",
    "    hits = list(Path.cwd().rglob(\"livinginsider_listing_urls.csv\"))\n",
    "    INPUT_CSV = hits[0] if hits else None\n",
    "    if not INPUT_CSV:\n",
    "        sys.exit(1)\n",
    "\n",
    "def click_consent(driver):\n",
    "    btns = driver.find_elements(By.CSS_SELECTOR, \"#onetrust-accept-btn-handler\")\n",
    "    btns += driver.find_elements(By.XPATH, \"//*[self::a or self::button][contains(., 'ยอมรับ')]\")\n",
    "    btns = [e for e in btns if e.is_displayed() and e.is_enabled()]\n",
    "    if btns:\n",
    "        driver.execute_script(\"arguments[0].click();\", btns[0])\n",
    "        time.sleep(0.3)\n",
    "\n",
    "def wait_present(driver, by, sel, timeout):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < timeout:\n",
    "        if driver.find_elements(by, sel):\n",
    "            return True\n",
    "        time.sleep(0.25)\n",
    "    return False\n",
    "\n",
    "def page_loaded(driver):\n",
    "    try_len = driver.execute_script(\"return document.body && document.body.innerHTML ? document.body.innerHTML.length : 0\")\n",
    "    return try_len and try_len > 1000\n",
    "\n",
    "def human_reload(driver, url):\n",
    "    driver.get(url)\n",
    "    click_consent(driver)\n",
    "    ok = wait_present(driver, By.CSS_SELECTOR, \"div.space_padding_top_data\", 8)\n",
    "    if ok or page_loaded(driver):\n",
    "        return True\n",
    "    driver.refresh()\n",
    "    click_consent(driver)\n",
    "    ok = wait_present(driver, By.CSS_SELECTOR, \"div.space_padding_top_data\", 8)\n",
    "    if ok or page_loaded(driver):\n",
    "        return True\n",
    "    driver.get(\"https://www.livinginsider.com/\")\n",
    "    time.sleep(1.2)\n",
    "    driver.get(url)\n",
    "    click_consent(driver)\n",
    "    ok = wait_present(driver, By.CSS_SELECTOR, \"div.space_padding_top_data\", 8)\n",
    "    return ok or page_loaded(driver)\n",
    "\n",
    "def parse_coords(text):\n",
    "    m = re.search(r\"(-?\\d+(?:\\.\\d+)?)\\s*,\\s*(-?\\d+(?:\\.\\d+)?)\", text)\n",
    "    return f\"{m.group(1)},{m.group(2)}\" if m else \"\"\n",
    "\n",
    "def scrape_one(driver, url):\n",
    "    ok = human_reload(driver, url)\n",
    "    if not ok:\n",
    "        return None\n",
    "    desc = first_text(driver.find_elements(By.CSS_SELECTOR, \"#desc-text-nl .wordwrap-box .wordwrap\"))\n",
    "    phone_nodes = driver.find_elements(By.CSS_SELECTOR, \"a.p-phone-contact[data-zcgrbcb]\")\n",
    "    phones = \", \".join(sorted({n.get_attribute(\"data-zcgrbcb\") for n in phone_nodes if n.get_attribute(\"data-zcgrbcb\")}))\n",
    "    vc = [e.text.strip() for e in driver.find_elements(By.CSS_SELECTOR, \".box-show-view-click .text-custom-gray-new\")]\n",
    "    return {\n",
    "        \"URL\": url,\n",
    "        \"Title\": first_text(driver.find_elements(By.CSS_SELECTOR, \"h1.font_sarabun.show-title\")),\n",
    "        \"Price\": first_text(driver.find_elements(By.CSS_SELECTOR, \".show_price_topic .price_topic b\")),\n",
    "        \"PricePerArea\": first_text(driver.find_elements(By.CSS_SELECTOR, \".show_price_topic .price_cal_area_text\")),\n",
    "        \"PropertyType\": first_text(driver.find_elements(By.CSS_SELECTOR, \".box_tag_topic_detail .box_tag_building\")),\n",
    "        \"PostType\": first_text(driver.find_elements(By.CSS_SELECTOR, \".box_tag_topic_detail .box_tag_posttype\")),\n",
    "        \"Size\": first_text(driver.find_elements(By.CSS_SELECTOR, \".detail_property_list_des_new .detail-property-list-text\")),\n",
    "        \"Description\": desc,\n",
    "        \"CreatedDate\": first_text(driver.find_elements(By.CSS_SELECTOR, \".row-detail-time .font_10_date\")),\n",
    "        \"Boosted\": first_text(driver.find_elements(By.XPATH, \"//div[contains(@class,'row-detail-time')]//span[contains(text(),'ดันประกาศล่าสุด')]\")),\n",
    "        \"Location\": first_text(driver.find_elements(By.CSS_SELECTOR, \".form-group.group-location-detail .detail-text-zone a\")),\n",
    "        \"Views\": vc[0] if len(vc) > 0 else \"\",\n",
    "        \"Clicks\": vc[1] if len(vc) > 1 else \"\",\n",
    "        \"Coordinates\": parse_coords(desc),\n",
    "        \"MaskedContacts\": phones\n",
    "    }\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.page_load_strategy = \"eager\"\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "with open(str(INPUT_CSV), \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    urls = [r[0].strip() for r in reader if r and r[0].strip()]\n",
    "\n",
    "rows = [r for u in urls if (r := scrape_one(driver, u)) for _ in [time.sleep(0.4)]]\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"URL\",\"Title\",\"Price\",\"PricePerArea\",\"PropertyType\",\"PostType\",\"Size\",\"Description\",\"CreatedDate\",\"Boosted\",\"Location\",\"Views\",\"Clicks\",\"Coordinates\",\"MaskedContacts\"])\n",
    "    w.writeheader()\n",
    "    for r in rows:\n",
    "        w.writerow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc471d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import re\n",
    "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "START_URL = \"https://baan.kaidee.com/c2p1-realestate/chiangmai\"\n",
    "OUTPUT_CSV_FILE = \"data/kaidee_listing_urls.csv\"\n",
    "PAGE_TIMEOUT = 40\n",
    "MAX_PAGES = 200\n",
    "PATTERN = re.compile(r\"https://baan\\.kaidee\\.com/product-\\d+\")\n",
    "\n",
    "def build_page_url(u, page):\n",
    "    if page <= 1:\n",
    "        return u\n",
    "    return (u if u.endswith(\"/\") else u + \"/\") + f\"p-{page}\"\n",
    "\n",
    "def wait_ready(driver, timeout):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < timeout:\n",
    "        if driver.execute_script(\"return document.readyState\") == \"complete\":\n",
    "            return True\n",
    "        time.sleep(0.2)\n",
    "    return False\n",
    "\n",
    "def deep_scroll(driver, rounds=12, pause=0.8):\n",
    "    prev = 0\n",
    "    for _ in range(rounds):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(pause)\n",
    "        cur = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if cur == prev:\n",
    "            break\n",
    "        prev = cur\n",
    "\n",
    "def extract_links(html):\n",
    "    return sorted(set(PATTERN.findall(html)))\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "page = 1\n",
    "all_urls = set()\n",
    "last_first = \"\"\n",
    "\n",
    "while page <= MAX_PAGES:\n",
    "    driver.get(build_page_url(START_URL, page))\n",
    "    wait_ready(driver, PAGE_TIMEOUT)\n",
    "    deep_scroll(driver, rounds=15, pause=0.8)\n",
    "    links = extract_links(driver.page_source)\n",
    "    if not links:\n",
    "        break\n",
    "    if page > 1 and links[0] == last_first:\n",
    "        break\n",
    "    last_first = links[0]\n",
    "    all_urls.update(links)\n",
    "    page += 1\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "if all_urls:\n",
    "    with open(OUTPUT_CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"url\"])\n",
    "        for u in sorted(all_urls):\n",
    "            w.writerow([u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "OUTPUT_CSV_FILE = \"data/kaidee_scraped_details.csv\"\n",
    "WAIT = 25\n",
    "\n",
    "cands = [\n",
    "    Path(\"data/kaidee_listing_urls.csv\"),\n",
    "    Path(\"kaidee_listing_urls.csv\")\n",
    "]\n",
    "INPUT_CSV = None\n",
    "for p in cands:\n",
    "    if p.exists():\n",
    "        INPUT_CSV = p\n",
    "        break\n",
    "if not INPUT_CSV:\n",
    "    for p in Path.cwd().rglob(\"kaidee_listing_urls.csv\"):\n",
    "        INPUT_CSV = p\n",
    "        break\n",
    "\n",
    "def scrape(driver, url):\n",
    "    w = WebDriverWait(driver, WAIT)\n",
    "    driver.get(url)\n",
    "    btns = driver.find_elements(By.CSS_SELECTOR, \"button[aria-label*='cookie i understand'], button[aria-label*='accept'], button:has(span[lang])\")\n",
    "    if btns:\n",
    "        driver.execute_script(\"arguments[0].click();\", btns[0])\n",
    "        time.sleep(0.3)\n",
    "    title_el = w.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.sc-747m9u-7\")))\n",
    "    price_el = w.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.sc-1w68tq4-0 span.sc-3tpgds-0\")))\n",
    "    desc_el = driver.find_elements(By.CSS_SELECTOR, \"div.sc-1kndlp1-0 p.inner-text\")\n",
    "    area_el = driver.find_elements(By.XPATH, \"//ul[@id='has-attributes']//li[.//span[text()='เนื้อที่']]//span//b\")\n",
    "    phone_els = driver.find_elements(By.CSS_SELECTOR, \"span.masked[data-value]\")\n",
    "    phones = sorted({e.get_attribute(\"data-value\").strip() for e in phone_els if e.get_attribute(\"data-value\")})\n",
    "    return {\n",
    "        \"URL\": url,\n",
    "        \"Title\": title_el.text.strip(),\n",
    "        \"Price\": price_el.text.strip(),\n",
    "        \"Area\": area_el[0].text.strip() if area_el else \"\",\n",
    "        \"Phone\": \", \".join(phones),\n",
    "        \"Description\": desc_el[0].text.strip() if desc_el else \"\"\n",
    "    }\n",
    "\n",
    "if INPUT_CSV:\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver = uc.Chrome(options=options, version_main=140)\n",
    "    with open(INPUT_CSV, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)\n",
    "        urls = [r[0].strip() for r in reader if r and r[0].strip()]\n",
    "    rows = []\n",
    "    for u in urls:\n",
    "        rows.append(scrape(driver, u))\n",
    "        time.sleep(1)\n",
    "    driver.quit()\n",
    "    with open(OUTPUT_CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"URL\", \"Title\", \"Price\", \"Area\", \"Phone\", \"Description\"])\n",
    "        w.writeheader()\n",
    "        w.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "START_URL = 'https://www.facebook.com/marketplace/chiangmai/propertyrentals/?exact=false'\n",
    "OUTPUT_CSV_FILE = 'data/facebook_marketplace_urls.csv'\n",
    "TARGET_URL_COUNT = 500\n",
    "WEBDRIVER_WAIT_TIMEOUT = 20\n",
    "\n",
    "def normalize_marketplace_url(u):\n",
    "    if not u:\n",
    "        return None\n",
    "    u = u.strip().split('?')[0].split('#')[0]\n",
    "    m = re.search(r'/marketplace/item/(\\d+)', u)\n",
    "    return f'https://www.facebook.com/marketplace/item/{m.group(1)}/' if m else None\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument('--disable-notifications')\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument(f'--user-data-dir=chrome-profile/fb-marketplace')\n",
    "\n",
    "driver = uc.Chrome(options=options, version_main=140)\n",
    "wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "\n",
    "driver.get(START_URL)\n",
    "time.sleep(7)\n",
    "\n",
    "popup_container_selector = \"div[aria-label='Accessible login form']\"\n",
    "popup_forms = driver.find_elements(By.CSS_SELECTOR, popup_container_selector)\n",
    "\n",
    "if popup_forms:\n",
    "    popup_form = popup_forms[0]\n",
    "    email_input = popup_form.find_element(By.NAME, \"email\")\n",
    "    pass_input = popup_form.find_element(By.NAME, \"pass\")\n",
    "    login_button = popup_form.find_element(By.CSS_SELECTOR, \"div[aria-label='Log in to Facebook']\")\n",
    "    email_input.send_keys(FACEBOOK_EMAIL)\n",
    "    pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "    login_button.click()\n",
    "    wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, popup_container_selector)))\n",
    "    time.sleep(5)\n",
    "\n",
    "all_listing_urls = set()\n",
    "stagnant_scrolls = 0\n",
    "\n",
    "while len(all_listing_urls) < TARGET_URL_COUNT:\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    item_link_selector = \"a[href*='/marketplace/item/']\"\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, item_link_selector)))\n",
    "    for element in driver.find_elements(By.CSS_SELECTOR, item_link_selector):\n",
    "        norm = normalize_marketplace_url(element.get_attribute('href'))\n",
    "        if norm:\n",
    "            all_listing_urls.add(norm)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        stagnant_scrolls += 1\n",
    "    else:\n",
    "        stagnant_scrolls = 0\n",
    "    if stagnant_scrolls >= 5:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "if all_listing_urls:\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['url'])\n",
    "        for url in sorted(list(all_listing_urls))[:TARGET_URL_COUNT]:\n",
    "            w.writerow([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "load_dotenv()\n",
    "FACEBOOK_EMAIL = os.getenv('FACEBOOK_EMAIL')\n",
    "FACEBOOK_PASSWORD = os.getenv('FACEBOOK_PASSWORD')\n",
    "INPUT_CSV_FILE = Path(\"data/facebook_marketplace_urls.csv\")\n",
    "OUTPUT_CSV_FILE = Path(\"data/facebook_marketplace_details.csv\")\n",
    "WEBDRIVER_WAIT_TIMEOUT = 25\n",
    "SCROLL_STEP_PX = 900\n",
    "MAX_SCROLL_TRIES = 15\n",
    "\n",
    "def scrape_marketplace_details(driver, url):\n",
    "    wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "    details = {'URL': url}\n",
    "    driver.get(url)\n",
    "    h1 = wait.until(EC.presence_of_element_located((By.TAG_NAME, 'h1')))\n",
    "    details['Title'] = h1.text.strip()\n",
    "    price_xpath = \"//h1/following-sibling::div[1]//span\"\n",
    "    details['Price'] = driver.find_element(By.XPATH, price_xpath).text.strip()\n",
    "    detail_items = driver.find_elements(By.CSS_SELECTOR, \"div[role='listitem'] span\")\n",
    "    details['Property_Details'] = ' | '.join([item.text.strip() for item in detail_items if item.text.strip()])\n",
    "    \n",
    "    desc_h2_xpath = \"//h2[.//span[contains(., 'คำอธิบาย')] or .//span[contains(., 'Description')]]\"\n",
    "    desc_h2_elements = driver.find_elements(By.XPATH, desc_h2_xpath)\n",
    "    if not desc_h2_elements:\n",
    "        last_height = 0\n",
    "        for i in range(MAX_SCROLL_TRIES):\n",
    "            driver.execute_script(f\"window.scrollBy(0, {SCROLL_STEP_PX});\")\n",
    "            time.sleep(0.8)\n",
    "            desc_h2_elements = driver.find_elements(By.XPATH, desc_h2_xpath)\n",
    "            if desc_h2_elements:\n",
    "                break\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "            if new_height == last_height:\n",
    "                driver.execute_script(\"window.scrollTo(0, Math.max(document.documentElement.scrollTop - 600, 0));\")\n",
    "                time.sleep(0.5)\n",
    "            last_height = new_height\n",
    "    \n",
    "    description_text = \"\"\n",
    "    if desc_h2_elements:\n",
    "        desc_h2 = desc_h2_elements[0]\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({behavior:'instant', block:'center'});\", desc_h2)\n",
    "        time.sleep(0.6)\n",
    "        containers = desc_h2.find_elements(By.XPATH, \"./following-sibling::div | parent::div/following-sibling::div | ancestor::div[1]/following-sibling::div\")\n",
    "        container = containers[0] if containers else None\n",
    "        if not container:\n",
    "            cands = driver.find_elements(By.XPATH, \"//h2[.//span[contains(., 'คำอธิบาย') or contains(., 'Description')]]/following::div[1]\")\n",
    "            container = cands[0] if cands else None\n",
    "        if container:\n",
    "            for _ in range(3):\n",
    "                see_more = container.find_elements(By.XPATH, \".//div[@role='button'][.//span[contains(., 'ดูเพิ่มเติม') or contains(., 'See more')]]\")\n",
    "                if see_more:\n",
    "                    if (\"ดูน้อยลง\" in see_more[0].text) or (\"See less\" in see_more[0].text):\n",
    "                        break\n",
    "                    driver.execute_script(\"arguments[0].click();\", see_more[0])\n",
    "                    time.sleep(0.6)\n",
    "                else:\n",
    "                    alt = desc_h2.find_elements(By.XPATH, \"./following-sibling::div//div[@role='button'][.//span[contains(., 'ดูเพิ่มเติม') or contains(., 'See more')]]\")\n",
    "                    if alt:\n",
    "                        driver.execute_script(\"arguments[0].click();\", alt[0])\n",
    "                        time.sleep(0.6)\n",
    "                    else:\n",
    "                        break\n",
    "            spans = container.find_elements(By.XPATH, \".//span[string-length(normalize-space())>0]\")\n",
    "            parts = [s.text.strip() for s in spans if s.text.strip()]\n",
    "            description_text = \"\\n\".join(parts) if parts else (container.get_attribute(\"innerText\") or \"\").strip()\n",
    "    details['Description'] = description_text\n",
    "    return details\n",
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument('--disable-notifications')\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('--no-first-run')\n",
    "options.add_argument('--no-default-browser-check')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--lang=en-US')\n",
    "options.add_argument('--user-data-dir=chrome-profile/fb-marketplace')\n",
    "options.page_load_strategy = 'eager'\n",
    "driver = uc.Chrome(options=options)\n",
    "driver.command_executor._client_config.timeout = 300\n",
    "driver.set_page_load_timeout(240)\n",
    "driver.set_script_timeout(240)\n",
    "\n",
    "wait = WebDriverWait(driver, WEBDRIVER_WAIT_TIMEOUT)\n",
    "driver.get(\"https://www.facebook.com/?locale=en_US\")\n",
    "time.sleep(7)\n",
    "\n",
    "popup_container_selector = \"div[aria-label='Accessible login form'], div[aria-label='เข้าสู่ระบบแบบช่วยการเข้าถึง']\"\n",
    "popup_forms = driver.find_elements(By.CSS_SELECTOR, popup_container_selector)\n",
    "if popup_forms:\n",
    "    popup_form = popup_forms[0]\n",
    "    email_input = popup_form.find_element(By.NAME, \"email\")\n",
    "    pass_input = popup_form.find_element(By.NAME, \"pass\")\n",
    "    login_button = popup_form.find_element(By.CSS_SELECTOR, \"div[aria-label*='Log in'], div[aria-label*='เข้าสู่ระบบ']\")\n",
    "    email_input.clear()\n",
    "    email_input.send_keys(FACEBOOK_EMAIL)\n",
    "    pass_input.clear()\n",
    "    pass_input.send_keys(FACEBOOK_PASSWORD)\n",
    "    login_button.click()\n",
    "    wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, popup_container_selector)))\n",
    "    time.sleep(5)\n",
    "\n",
    "with open(INPUT_CSV_FILE, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    urls_to_scrape = [row[0].strip() for row in reader if row and row[0].strip()]\n",
    "\n",
    "all_details = []\n",
    "for url in urls_to_scrape:\n",
    "    all_details.append(scrape_marketplace_details(driver, url))\n",
    "    time.sleep(2.5)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "if all_details:\n",
    "    headers = ['URL', 'Title', 'Price', 'Property_Details', 'Description']\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=headers)\n",
    "        w.writeheader()\n",
    "        w.writerows(all_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
